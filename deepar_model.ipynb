{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Here we create base class for deepar model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from torch import Tensor, log, exp\n",
    "\n",
    "class DeepAR(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size: int,\n",
    "            hidden_size: int,\n",
    "            input_size: int,\n",
    "            likelihood: str = 'normal',\n",
    "            device: str = 'cpu'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This class instantiates DeepAR.\n",
    "\n",
    "        :param batch_size: size of the batch\n",
    "        :param hidden_size: number of features in hidden state of rnn cell\n",
    "        :param inout_size: number of expected features in the input tensor\n",
    "        :param likelihood: desired likelihood\n",
    "        :param device: device to calculate on\n",
    "        \"\"\"\n",
    "        super(DeepAR, self).__init__()\n",
    "        # here we initialize hidden states\n",
    "        self._h_0 = torch.zeros((batch_size, hidden_size), device=device)\n",
    "        self._c_0 = torch.zeros((batch_size, hidden_size), device=device)\n",
    "        self._likelihood = likelihood\n",
    "        self._device = device\n",
    "\n",
    "        # here we create base architecture of LSTM cell\n",
    "        self._lstm_cell = nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "    @property\n",
    "    def h_0(self):\n",
    "        return self._h_0\n",
    "\n",
    "    @property\n",
    "    def c_0(self):\n",
    "        return self._c_0\n",
    "\n",
    "    @property\n",
    "    def likelihood(self):\n",
    "        return self._likelihood\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    @property\n",
    "    def lstm_cell(self):\n",
    "        return self._lstm_cell\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_tensor: Tensor # [batch_size, seq_len, input_size]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward method of our model\n",
    "        :param input_tensor: input tensor [batch_size, seq_len, input_size]\n",
    "        :return: output_tensor: output tensor contains parameters or desired distribution [batch_size, seq_len, num_pars]\n",
    "        \"\"\"\n",
    "        batch_size, hidden_size = self.h_0.shape[0], self.h_0.shape[1]\n",
    "        input_size, seq_len = input_tensor.shape[2], input_tensor.shape[1]\n",
    "        num_pars = 2\n",
    "        if self.likelihood == 'normal':\n",
    "            output_tensor = torch.zeros((batch_size, seq_len, num_pars), device=self.device)\n",
    "        else:\n",
    "            raise NotImplementedError('this likelihood not yet implemented, gl&hf')\n",
    "        # here we iterate through all cells (seq_len)\n",
    "        num_cells = input_tensor.shape[1]\n",
    "\n",
    "        if self.likelihood == 'normal':\n",
    "            for cell_index in range(num_cells):\n",
    "                self._h_0, self._c_0 = self.lstm_cell(input_tensor[:, cell_index, :], (self.h_0, self.c_0))\n",
    "                mean = nn.Linear(in_features=hidden_size, out_features=1)(self.h_0)\n",
    "                variance = log(1 + exp(nn.Linear(in_features=hidden_size, out_features=1)(self.h_0)))\n",
    "                output_tensor[:, cell_index, 0] = torch.flatten(mean)\n",
    "                output_tensor[:, cell_index, 1] = torch.flatten(variance)\n",
    "        else:\n",
    "            raise NotImplementedError('this likelihood not yet implemented, gl&hf')\n",
    "\n",
    "        return output_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.2897,  0.8674],\n         [ 0.2523,  0.7870],\n         [-0.2335,  0.5151]],\n\n        [[-0.2897,  0.8674],\n         [ 0.2523,  0.7870],\n         [-0.2335,  0.5151]]], grad_fn=<CopySlices>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, input_size, hidden_size = 2, 3, 4, 5\n",
    "model = DeepAR(input_size=input_size, batch_size=batch_size, hidden_size=hidden_size)\n",
    "input_tensor = torch.zeros((batch_size, seq_len, input_size))\n",
    "output_tensor = model(input_tensor)\n",
    "output_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}